---
title             : "The asymmetry between generic truth conditions and implied prevalence"
shorttitle        : "Generic asymmetry"

author: 
  - name          : "Michael Henry Tessler"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 316, Stanford, CA 94305"
    email         : "mhtessler@stanford.edu"
  - name          : "Noah D. Goodman"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
    
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  - \usepackage{amsmath}
  - \usepackage{graphicx}
  - \usepackage{subcaption}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  
author_note: >
  This manuscript is currently in prep. Comments or suggestions should be directed to MH Tessler.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["generics.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}

\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}
\newcommand{\ndg}[1]{{\textcolor{Green}{[ndg: #1]}}}
\newcommand{\red}[1]{{\textcolor{Red}{#1}}}


```{r load_packages, include = FALSE}
library("papaja")
library(tidyverse)
library(cowplot)
library(ggthemes)
library(RColorBrewer)
library(ggpirate)
theme_set(theme_few())
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

# Introduction

\red{look at things that cite Cimpian et al. (2010) and see if people are discussing the asymmetry in the philosophical literature}

Generic statements (e.g., "Birds fly") convey generalizations about categories [@Carlson1977; @Carlson1995; @Leslie2008].
This kind of language has caught the attention of psychologists, linguists, and philosophers beacuse it is widely prevalent in everyday conversation and child-directed speech [@Gelman1998; @Gelman2008; @GelmanEtAl2004], while at the same time having formal properties that are difficult to characterize [@Carson1995]. 

Generic statement can be intuitively true under a wide range of statistical conditions. 
"Birds fly" is true of most birds, but "Ducks lay eggs" is only true of adult, fertile, female ducks, which make up less than 50\% of the category.
"Mosquitos carry malaria" is intuitively true despite less than 1\% of category actually having the property.
Despite these variable *truth conditions*, it has been noted that generic statements often carry the *implied prevalence* of a universal or near-universal quantifier [@Abelson1966; @Gelman2002; @Cimpian2010]. 
When both children and adults learn "Bears like to eat ants", they tend to think that *almost all* bears like to eat ants [@Gelman2002].

Thus, there appears to be a surprising d\'{e}colage between the truth conditions and interpretations of generic language: Interpretations are often strong while truth conditions are flexible. 
@Cimpian2010 found that upon reading a generic (e.g., "Glippets have yellow fur."), participants infer that the *implied prevalence* is high (e.g., almost all glippets have yellow fur).
By contrast, participants endorse generics for a wide range of prevalence levels (e.g., even when 30\% of glippets have yellow fur). 
By quantitatively comparing the two measurements, @Cimpian2010 found an asymmetry between between truth conditions and implied prevalence of generic statements but not for quantified statementse involving *all* or *most*.

Not all generics have strong interpretations, however. 
"Mosquitos carry malaria" really seems to only have the quantificational force of an existential claim, meaning *some mosquitos carry malaria*.
Weak interpretations from generics have been observed in tasks having participants draw inferences about individual members of a kind [@Khemlani2009; @Khemlani2012] as well as asking about implied prevalence [@Cimpian2010; Expt. 3].
Coupled with the truth conditions measurements, @Cimpian2010 found that a significant reduction in the asymmetry for generics about accidental properties (e.g., "Glippets have wet fur.").

When and how will the asymmetry between truth conditions and implied prevalence manifest?
\red{[check cimpian's discussion section]}
Here, we draw on the same computational framework to address this question. 
We show through simulation various conditions under which the asymmetry appears and when it is predicted to disappear or even reverse.
Then, we replicate the original asymmetry findings of @Cimpian2010 while expanding the stimulus set to reveal even more variability in the asymmetry.
We then extend these findings to a larger-scale study using a more diverse stimulus set.
In addition to revealing the quantitative intracacies of the asymmetry, our very same model is able to account for both truth conditions and implied prevalence simultaneously. 

# The asymmetry between truth conditions and interpretations

The empirical asymmetry between truth conditions and interpretations was reported by @Cimpian2010.
Truth conditions data result from an endorsement task, a two-alternative forced choice (2AFC) paradigm (as explored in Chapter 3).
Interpretation data are prevalence ratings, typically on a 101-pt scale (e.g., the percentage of the category with the property).
Thus, these two constructs are not in the same measurement space; one must be transformed into the other.

To accomplish this, @Cimpian2010 turned the 2AFC endorsement data and computed the average prevalence level at which participants endorse the generic (*average truth conditions*).
*Average truth conditions* is analagous to an average threshold. 
To compute average truth conditions, you subset the endorsement data to look at only the trials where a participant endorsed the generic. 
On a participant-wise basis, you take the mean of the referent prevalence levels (empirically supplied to participants) at which the participant endorsed the generic.
For example, if a participant endorsed the generic at 50%, 70%, and 90% prevalence levels, their *average truth conditions* would be 70%. 
Note that as participants become more lenient with the generic (endorsing it at lower prevalence levels), their corresponding average truth conditions will lower.
The theoretical minimum average truth conditions is 50%, for a participant who endorsed the generic at all prevalence levels.^[
  Average truth conditions could, in principle, be less than 50% if a participant only endorses the statement at low prevalence levels and then rejects the statement at high prevalence levels. We do not expect this behavior for the generic. 
]
If a participant fails to endorse the generic for all prevalence levels, @Cimpian2010 assigned them an average truth conditions of 100%, because presumably the participant would only endorsed the generic if it was true of 100% of members.

\red{Figure 1} shows the average truth conditions for a variety of semantic hypotheses.

```{r asymmetrySimulations, fig.width = 10, fig.asp = 0.6, fig.cap="Model simulations"}
load(file = "cached_results/modelSims-priors_fixedT_uncertainT.RData")
get.colors <- function(pal) brewer.pal(brewer.pal.info[pal, "maxcolors"], pal)
spectrum.color.palette <- get.colors("Blues")
load("cached_results/modelSims-asymmetry.RData")

fig.sims.priors <- ggplot(sims.combined %>%
         filter(
           PriorShape %in% c("uniform", "biological_rare", "accidental_rare"),
           src %in% c("priors")
           ) %>%
         mutate(PriorShape = factor(PriorShape, levels = c("uniform", "biological_rare", "accidental_rare"),
                                    labels = c("uniform", "biological", "accidental")),
                src = factor(src, levels = c( "priors"),
                             labels = c(
                               '\n prevalence prior'
                                        ))), 
       aes(x = state))+
    geom_density(aes(y = ..scaled..), fill= 'black', size = 0.6, alpha = 0.7, adjust = 1.1)+
    theme_few() +
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    ylab("Probability density (scaled)") +
    xlab("Prior Prevalence")+
    #scale_color_solarized()+
    #scale_fill_solarized()+
    facet_grid(PriorShape~src, scales = 'free')+
    theme(strip.text.y = element_text(angle = 0),
          legend.position = "none"
          )


fig.sims.distributions <- ggplot(sims.combined %>%
         filter(
           PriorShape %in% c("uniform", "biological_rare", "accidental_rare"),
           src == "posteriors"
           #src %in% c("fixed_0.1", "fixed_0.33", "fixed_0.5", "posteriors")
           ) %>%
         mutate(PriorShape = factor(PriorShape, levels = c("uniform", "biological_rare", "accidental_rare"),
                                    labels = c("Xs Y\n[uniform]", "Xs fly\n[biological]", "Xs carry malaria \n [accidental]")),
                src = factor(src, levels = c("posteriors"),
                             labels = c('generic\n(uncertain threshold)'))),
                # src = factor(src, levels = c( "fixed_0.1", "fixed_0.33",
                #                               "fixed_0.5", "posteriors"),
                #              labels = c(
                #            #    'prevalence prior',
                #                '"some"\n(threshold = 0.01)',
                #                '"more than a third"\n(threshold = 0.33)',
                #               '"most"\n(threshold = 0.5)',
                #                'generic\n(uncertain threshold)'
                #                         ))), 
       aes(x = state, fill = src, color = src))+
    geom_density(aes(y = ..scaled..), 
                 color ='black', fill = 'grey50', size = 0.6, alpha = 0.7, adjust = 1.1)+
    theme_few() +
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    ylab("Scaled posterior density") +
    xlab("Implied Prevalence")+
    # scale_fill_brewer(palette=2, type = "seq", direction = -1)+
    # scale_color_brewer(palette=2, type = "seq", direction = -1)+
    #scale_color_manual( values =  c(spectrum.color.palette[c(8,5,2)], "#238b45"))+
    #scale_fill_manual( values = c(spectrum.color.palette[c(8,5,2)], "#238b45") )+
    facet_grid(PriorShape~src, scales = 'free')+
    theme(strip.text.y = element_blank(),# element_text(angle = 0, size = 12),
          legend.position = "none",
          axis.title.y = element_blank())

fig.sims.truthJudgments <- s1.simulations %>%
  filter(model == "generic") %>%
  mutate(prior = factor(prior, levels = c("uniform", "biological_rare", "accidental_rare"),
                                    labels = c("uniform", "biological", "accidental"))) %>%
  ggplot(., aes ( x = referent_prevalence, y = endorsement,
                  linetype = prior))+
  geom_point()+
  geom_line()+
  theme(legend.position = c(0.8, 0.4) ,
        legend.title = element_blank())+
    scale_x_continuous(breaks = c(0, 0.5, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 0.5, 1), limits= c(0, 1))+
  ylab("Endorsement probability")+
  xlab("Referent prevalence")


fig.sims.asymmetry <- m.gen.asym %>%
  filter(src == "posteriors") %>%
  mutate(src = factor(src),
         PriorShape = factor(PriorShape, levels = c("biological_rare","accidental_rare",   "uniform"),
                                    labels = c( "biological",  "accidental","uniform")),
         model = factor(model, levels = c("S1", "L0"), labels = c("Truth conditions", "Implied prevalence"))) %>%
  ggplot(., aes(x = PriorShape, y = expval, 
                fill = model))+
  scale_fill_solarized() + 
      scale_y_continuous(breaks = c(0, 0.5, 1), limits= c(0, 1))+
  ylab("Average prevalence")+
  geom_col(position= position_dodge(), color = 'black')+
  #geom_errorbar(position = position_dodge())+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position = c(0.75, 0.85),
        legend.title = element_blank(),
        axis.title.x = element_blank())


cowplot::plot_grid(
  fig.sims.priors + theme(plot.margin = unit(c(6, 3, 6, 0), "pt")), 
  fig.sims.distributions + theme(plot.margin = unit(c(6, 6, 6, 0), "pt")),
  cowplot::plot_grid(
      fig.sims.truthJudgments + theme(plot.margin = unit(c(18, 3, 6, 0), "pt")), 
      fig.sims.asymmetry + theme(plot.margin = unit(c(6, 0, 6, 0), "pt")),
      ncol = 1,
      labels = c("C","D"),
      rel_heights  = c(1, 1.25)
      ),
  #fig.sims.bars+ theme(plot.margin = unit(c(6, 0, 0, 0), "pt")),
  nrow = 1,
  labels = c("A", "B", ""),
  rel_widths = c(0.8, 0.6, 1)
)
```
<!-- - Model figure: -->
<!--   - Prior1, L("Generic1"), S: x=%, y= endorse, group = prior,  ATC & IP: bar plot (x = model) -->
<!--   - Prior2, L("Generic2"), S: x=%, y= endorse,  ATC & IP: bar plot (x = model) -->
<!--   - Prior3, L("Generic3"), S: x=%, y= endorse,  ATC & IP: bar plot (x = model) -->

<!-- 
Computing ATC for model should just be the mean of the production probabilities...
This probably is the same as the Cimpian sampling method, though won't have a way of constructing the variance..
thus the sampling method may be preferred for constructing the variance
-->





To quantitatively compare these two measurements, @Cimpian2010

The computational model of generic interpretation predicts that the implied prevalence of a generic statement is an interaction between background knowledge (formalized as a prevalence prior) and an underspecified threshold semantics. 
I have shown in Chapter 2 how this model predicts context-sensitive interpretations of generic sentences. 
The implied prevalence of a generic may be very strong (e.g., "Wugs have four legs") or very weak (e.g., "Lorches live in zoos").
The implied prevalence of a generic 

# Experiment 1: Replication and extension of Cimpian et al. (2010)

# Experiment 2: Property-specific asymmetries

<!-- \subsubsection*{Method} -->

<!-- We re-analyze the data from Expt.~2b as the \emph{implied prevalence} data. -->
<!-- The following paradigm is to measure the corresponding \emph{truth conditions}. -->

<!-- \paragraph*{Participants} -->

<!-- We recruited 40 participants over MTurk.   -->
<!-- %We chose a sample size at least twice as large as the original study by \citeA{Cimpian2010} (original n=20), and to match Expt.~2b.  -->
<!-- All participants were native English speakers.  -->
<!-- None of the participants completed Expt.~2b (interpretations of novel generics). -->
<!-- The experiment took about 5 minutes and participants were compensated \$0.60. -->

<!-- \paragraph*{Procedure and materials} -->

<!-- The cover story and materials were the same as in Expt.~2b. -->
<!-- On each trial, participants were given a statement about a property's prevalence within a novel kind (e.g. \emph{50\% of feps have yellow fur.}). Participants were then asked whether or not they agreed or disagreed with the corresponding generic sentence (e.g. \emph{Feps have yellow fur.}). Prevalence varied between 10, 30, 50, 70, and 90\%. -->

<!-- The experiment consisted of 25 trials: 5 trials for each of 5 types of properties measured in Expt.~2a (part, color part, vague part, common accidental, rare accidental).  -->
<!-- Each prevalence level appeared once for each property type (5 prevalence levels x 5 property types).  -->

<!-- \subsubsection*{Analysis and results} -->

<!-- For both behavioral data and model predictions (Eq.~\ref{eq:S2}) we computed the average prevalence that led to an assenting judgment (the \emph{average prevalence score}), for each property type and participant, following the procedure used by \citeA{Cimpian2010}. -->
<!-- For example, if a participant agreed with the generic whenever the prevalence was 70\% or 90\% and disagreed at the other prevalence levels, that participant received an \emph{average prevalence score} of 80\%. -->

<!-- For our pair of models, there are two parameters (the two speaker optimality parameters). -->
<!-- We infer them using the same Bayesian data analytic approach as before.  -->
<!-- The MAP and 95\% HPD intervals for $\lambda_1$ is 19.5 [10.5, 19.9] and $\lambda_2$ is 0.4 [0.34, 0.49]. -->
<!-- We then subjected the generic endorsement model to the same procedure as the human data.  -->
<!-- The speaker model $S_2$ returns a posterior probability of producing the generic, for each level of prevalence.  -->
<!-- We sample a response (\emph{agree} / \emph{disagree}) from this posterior distribution for each prevalence level, simulating a single subject's data. -->
<!-- As with the human data, we took the trials where the model agreed with the generic, and took the mean of the prevalence levels corresponding to those trials, giving us the average prevalence at which the model assented to the generic. -->
<!-- We repeated this for each type of property 40 times to simulate a sample of 40 participants.  -->
<!-- We repeated this procedure 1000 times to bootstrap 95\% confidence intervals. -->

<!-- The generic endorsement model (speaker $S_2$) predicted that \emph{average truth conditions} should not vary appreciably across the different types of properties, consistent with the fact that generics are acceptable for broad range of prevalence levels for all property types. -->
<!-- A similar absence of a gradient was observed in the human data ($\beta = 2.82; SE = 4.02; t(39) = 0.70; p = 0.49$; Figure \ref{fig:exp2b}, dotted lines).  -->
<!-- Interpretations of generic utterances are stronger than their average truth conditions for the biological properties but not for the accidental properties (Figure \ref{fig:exp2b}) with both human data, replicating \citeA{Cimpian2010}, and the model; the extent of the difference is governed by prior property knowledge (mean prevalence when present $\gamma$, from Expt.~2a). -->
<!-- The listener and speaker pair of models predicts human endorsements and interpretations of novel generic utterances well ($r^2(10) = 0.87$, MSE = 0.008). -->
<!-- Thus, our model predicts that the asymmetry between truth conditions and implied prevalence should hold, but only for properties with the most extreme prior beliefs. -->




# Discussion


# References


```{r create_r-references}
r_refs(file = "generics.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
