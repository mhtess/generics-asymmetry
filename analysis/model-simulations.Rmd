---
title: "Asymmetry model simulations"
output: html_notebook
---


```{r libraries, cache = F}
library(rwebppl)
library(xtable)
library(tidyverse)
library(forcats)
library(langcog)
library(ggthemes)
library(ggrepel)
library(jsonlite)
library(gridExtra)
library(knitr)
library(kableExtra)
library(cowplot)
library(magick)
theme_set(theme_few())
estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
logmeanexp <- function(x){
  x.num <- as.numeric(x)
  xstar = max(x.num)
  return(xstar + log(mean(exp(x.num - xstar))))
}

compute_r2 <- function(df,v1, v2, sigfigs = 3){
  return(format(cor(df[[v1]], df[[v2]])^2, digits = sigfigs))
}

compute_mse <- function(df, v1, v2, sigfigs = 3){
  return(format(mean( (df[[v1]]-df[[v2]])^2), digits = sigfigs))
}

project.path <- "../"
options("scipen"=10) 
```

# RSA model

```{r rsaHelpers}
rsaHelpers <- '
var probability = function(Dist, x) {
    return Math.exp(Dist.score(x));
}
var targetUtterance = "generic";

var round = function(x){
  return Math.round(x*1000)/1000
}

var thetaBins = map(round, _.range(0.01, 0.98, 0.01))
// var thetaBins = [
//    0.01, 0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,
//    0.5, 0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95
 // ]
var thetaPrior = Infer({model: function(){
 return uniformDraw(thetaBins)
}});

// var bins = map(round, _.range(0.01, 0.99, 0.01))

var lb = 0, ub = 1, diff = 0.01;
var bins = map(round, _.range(lb, ub + diff, diff))

// var bins = [
  // 0.01,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,
  // 0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99
// ];

var meaning = function(utt,state, theta) {
  return utt=="generic"? state > theta :
         utt=="generic is false"? state<=theta :
         utt=="silence"? true :
         utt=="some"? state>0.01:
         utt=="most"? state> 0.5:
         utt=="all"? state >= 0.99:
         true
}

var mixture = data.prior.mix[0];
var priorParams = data.prior.params[0];

var statePrior = Infer({model: function(){
  var component = flip(mixture);
  return component ?
    categorical({
      vs: bins,
      ps: map(function(b) {
        return probability(Beta(priorParams), b) + Number.EPSILON
      }, bins )
    }) :
    categorical({
      vs: bins,
      ps: map(function(b) {
        return probability(Beta({a:1,b:50}), b) + Number.EPSILON
      }, bins )
    })
}});
'
```

```{r rsaInterpretationModels}
no.utterance.model <- 'statePrior'

fixed.threshold.model <- '
var fixedThresholdInterpreter = function(threshold) {
  Infer({model: function(){
  // var state = sample(Beta( flip(mixture) ? priorParams : {a:1,b:100}))
  var state = sample(statePrior)
  condition( state > threshold)
    return {
      state: state
  }
 // }, method: "rejection", samples: 20000, burn:5000, verbose: T})}
 }, method: "enumerate"})}
'

uncertain.threshold.model <- '
var uncertainThresholdInterpreter = function() {
  Infer({model: function(){
   var state = sample(statePrior) // sample(Beta( flip(mixture) ? priorParams : {a:1,b:100}))
  var theta = sample(thetaPrior);
      // factor( Math.log(state) )
condition(state > theta)
    return {
      state: state, 
  }
  }, method: "enumerate"})}
'
```



```{r}
l1.model <- '
var alpha = data.alpha[0]
var utterances = [
  "generic",
  "silence"
];

var cost_gen = data.cost[0];

var uttCosts = map(function(u) {
  return Math.exp(u == "generic" ? -cost_gen : 0)
}, utterances)

var utterancePrior = Infer({model: function(){
  return utterances[discrete(uttCosts)]
}});

var listener0 = cache(function(utterance, thresholds) {
  Infer({model: function(){
    var state = sample(statePrior)
    var m = meaning(utterance, state, thresholds);
    condition(m);
    return state;
  }})
}, 10000);

var speaker1 = cache(function(state, thresholds) {
  Infer({model: function(){
    var utterance = sample(utterancePrior);
    var L0 = listener0(utterance, thresholds);
    factor(alpha*L0.score(state));
    return utterance;
  }})
}, 10000);

var greaterThanThresholdBins = _.range(lb, ub, diff)
var lessThanThresholdBins = _.range(lb+diff, ub+diff, diff)

var listener1 = cache(function(utterance) {
  Infer({model: function(){
    var thresholds = uniformDraw(greaterThanThresholdBins)
    var state = sample(statePrior)
    var S1 = speaker1(state, thresholds)
    observe(S1, utterance)
    return {state}
  }})
}, 10000);
'
```




```{r simulationCalls}
fixed.threshold.calls <- '
_.fromPairs(map(function(t){return [t, fixedThresholdInterpreter(t)]}, [_.min(thetaBins), 0.5]))
'
no.utterance.call <- ' 
    statePrior
'
uncertain.threshold.call <- '
  uncertainThresholdInterpreter()
'

l1.call <- '
  listener1("generic")
'
```

```{r simulationRuns}
priorNames <- c(
  "uniform",
#  "uniform_rare", 
  #"biological_common", 
  "biological_rare",
  #"accidental_common",
  "accidental_rare"
)

priorShapes <- list(
  uniform =  list(params = data.frame(a = 1, b = 1), mix = 1), 
  uniform_rare =  list(params = data.frame(a = 1, b = 1), mix = 0.4), 
  biological_common =  list(params = data.frame(a = 30, b = 1), mix = 1), 
  biological_rare =  list(params = data.frame(a = 30, b = 1), mix = 0.4), 
  accidental_common =  list(params = data.frame(a = 2, b = 10), mix = 1),
  accidental_rare =  list(params = data.frame(a = 2, b = 10), mix = 0.4)
)

sims.fixed.thresholds <- data.frame()
sims.priors <- data.frame()
sims.uncertain.thresholds <- data.frame()
sims.l1 <- data.frame()
for (p in priorNames){

  inputData = list(prior = priorShapes[[p]])
  rs.fixed.threshold.model <- webppl(paste(rsaHelpers, fixed.threshold.model, fixed.threshold.calls, sep = '\n'), data = inputData, data_var = "data")
  
  rs.uncertain.threshold.model <- webppl(paste(rsaHelpers, uncertain.threshold.model, uncertain.threshold.call, sep = '\n'), data = inputData, data_var = "data")
  
  # for (a in c(1, 3, 5, 10, 20)){
  #   
  #   for (cost in c(0, 0.5, 1, 2, 3)){
  #     
  # 
  #       rs.l1.model <- webppl(paste(rsaHelpers, l1.model, l1.call, sep = '\n'), 
  #                         data = list(prior = priorShapes[[p]],
  #                                     alpha = a,
  #                                     cost = cost), data_var = "data")
  #     sims.l1 <- bind_rows(
  #       sims.l1, get_samples(rs.l1.model, 20000) %>% 
  #         mutate(PriorShape = p, alpha = a, cost = cost)
  #     )
  #   }
  # 
  # }

  
  
  rs.prior <- webppl(paste(rsaHelpers, no.utterance.model, no.utterance.call, sep = '\n'), data = inputData, data_var = "data")

  sims.fixed.thresholds <- bind_rows(sims.fixed.thresholds,
    bind_rows(
      mutate(get_samples(data.frame(rs.fixed.threshold.model$`0.01`) %>% rename(prob = probs), 20000), threshold = 0.1) ,
      mutate(get_samples(data.frame(rs.fixed.threshold.model$`0.5`) %>% rename(prob = probs), 20000), threshold = 0.5)
      #mutate(get_samples(data.frame(rs.fixed.threshold.model$`0.7`) %>% rename(prob = probs), 20000), threshold = 0.7),
      #mutate(get_samples(data.frame(rs.fixed.threshold.model$`0.9`) %>% rename(prob = probs), 20000), threshold = 0.9)
    ) %>% 
      mutate(PriorShape = p, alpha = 0, cost =0)
    )

  sims.uncertain.thresholds <- bind_rows(
    sims.uncertain.thresholds, 
    get_samples(rs.uncertain.threshold.model, 20000) %>% mutate(PriorShape = p, alpha = 0, cost =0)
    #rs.uncertain.threshold.model %>% select(value) %>% rename(state = value) %>% mutate(PriorShape = p)
    )
  
  
  sims.priors <- bind_rows(
    sims.priors, 
    get_samples(rs.prior, 20000) %>% rename(state = support) %>% mutate(PriorShape = p, alpha =0, cost = 0)
    #rs.prior %>% select(value) %>% rename(state = value) %>% mutate(PriorShape = p)
    )
  
  print(p)
}


sims.combined <- bind_rows(
    sims.priors %>% mutate(src = 'priors'),
    sims.uncertain.thresholds %>% mutate(src = 'posteriors'),
    sims.fixed.thresholds %>%
      mutate(src = paste('fixed', threshold, sep = "_")) %>%
      select(-threshold),
    sims.l1 %>% 
      mutate(src = "L1")
    )

```


```{r posterior expectations}
sims.combined %>% 
  filter(PriorShape == "uniform", src == "posteriors") %>%
  summarize( expval = mean(state))
```



```{r viz priors only}
ggplot(sims.combined %>%
         filter(
           PriorShape %in% c("uniform", "biological_rare", "accidental_rare"),
           src %in% c("priors")
           ) %>%
         mutate(PriorShape = factor(PriorShape, levels = c("uniform", "biological_rare", "accidental_rare"),
                                    labels = c("Xs Y (uniform)", "Xs fly (biological)", "Xs carry malaria (accidental)")),
                src = factor(src, levels = c( "priors"),
                             labels = c(
                               'prevalence prior'
                                        ))), 
       aes(x = state))+
    #geom_density_ridges(scale = 0.9, alpha = 0.7)+
    geom_density(aes(y = ..scaled..), fill= 'black', size = 0.6, alpha = 0.7, adjust = 1.1)+
    theme_few() +
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    # geom_label(data = s1.simulations.relabeled.2,
    #             aes(x = xlabpos, y=0.25, label = category),
    #             label.padding = unit(0.075, "lines"),
    #               family = 'Palatino', fontface = 'bold', size = 3.2, inherit.aes =F, force = 15)+
    ylab("Probability density (scaled)") +
    xlab("Prior Prevalence")+
    scale_color_solarized()+
    scale_fill_solarized()+
    facet_grid(PriorShape~src, scales = 'free')+
    theme(strip.text.y = element_blank(),
          legend.position = "none"
          #plot.margin=unit(c(0,0,0,0),"cm")
          )

```


```{r}
ggplot(sims.combined %>%
         filter(
           PriorShape %in% c("uniform", "biological_rare", "accidental_rare"),
           src %in% c("fixed_0.1", "fixed_0.5", "posteriors")
           ) %>%
         mutate(PriorShape = factor(PriorShape, levels = c("uniform", "biological_rare", "accidental_rare"),
                                    labels = c("Xs Y    \n[uniform]", "Xs fly      \n[biological]", "Xs carry malaria \n [accidental]         ")),
                src = factor(src, levels = c( "fixed_0.1", "fixed_0.5", "posteriors"),
                             labels = c(
                           #    'prevalence prior',
                               '"some" (threshold = 0.01)',
                              '"most" (threshold = 0.5)',
                               'generic (uncertain threshold)'
                                        ))), 
       aes(x = state, fill = src, color = src))+
    #geom_density_ridges(scale = 0.9, alpha = 0.7)+
    geom_density(aes(y = ..scaled..), size = 0.6, alpha = 0.7, adjust = 1.1)+
    theme_few() +
    scale_x_continuous(breaks = c(0, 1), limits= c(0, 1))+
    scale_y_continuous(breaks = c(0, 1), limits= c(0, 1))+
    # geom_label(data = s1.simulations.relabeled.2,
    #             aes(x = xlabpos, y=0.25, label = category),
    #             label.padding = unit(0.075, "lines"),
    #               family = 'Palatino', fontface = 'bold', size = 3.2, inherit.aes =F, force = 15)+
    ylab("Scaled posterior density") +
    xlab("Implied Prevalence")+
    scale_color_solarized()+
    scale_fill_solarized()+
    facet_grid(PriorShape~src, scales = 'free')+
    theme(strip.text.y = element_text(angle = 0, hjust =0, size = 12),
          legend.position = "none",
          axis.title.y = element_blank()
          #plot.margin=unit(c(0.5,0.5,1.5,0.5),"cm")
          )
```

```{r simluationEndorsementModel}
s1.model <- '
var interpreter = cache(function(utterance, fixed_threshold) {
  Infer({model: function(){
    var state = sample(statePrior)
    // display(fixed_threshold ? 1 : 0)
    var theta = fixed_threshold ? fixed_threshold : sample(thetaPrior) 
    condition(meaning(utterance, state, theta))
    return state
 }})}, 10000)

var alpha = data.alpha[0]

var endorser = function(featureProb, fixed_threshold){
  Infer({model: function(){
    var endorsement = uniformDraw(["generic","silence"])
    var L0 = interpreter(endorsement, fixed_threshold)
    factor(alpha * L0.score(featureProb))
    return endorsement == "generic" ? 1 : 0
  }})
}
// console.log(data.referent_prevalence[0])
// var returnObj = {
 // generic: probability(endorser(data.referent_prevalence[0]), "generic"),
 // some: data.referent_prevalence[0] >  _.min(thetaBins) ?  1: 0, //probability(endorser(data.referent_prevalence[0], _.min(thetaBins)), "generic"),
 // most: data.referent_prevalence[0] >  0.5 ?  1: 0 //probability(endorser(data.referent_prevalence[0], 0.5), "generic")
// }
//returnObj
var totalProbability = sum(map(function(x){return Math.exp(statePrior.score(x))}, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))
map(function(x){
  return {prevalence: x, endorsementProb: expectation(endorser(x)),
          needProbability: Math.exp(statePrior.score(x)),
          normalizedNeedProb : Math.exp(statePrior.score(x)) / totalProbability}
}, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
'

```

```{r simluationEndorsementModelRuns}

priorNames <- c(
  "uniform",
#  "uniform_rare", 
  #"biological_common", 
  "biological_rare",
  #"accidental_common",
  "accidental_rare"
)
  
priorShapes <- list(
  uniform =  list(params = data.frame(a = 1, b = 1), mix = 1),
  uniform_rare =  list(params = data.frame(a = 1, b = 1), mix = 0.4),
  biological_common =  list(params = data.frame(a = 30, b = 1), mix = 1),
  biological_rare =  list(params = data.frame(a = 30, b = 1), mix = 0.4),
  accidental_common =  list(params = data.frame(a = 2, b = 10), mix = 1),
  accidental_rare =  list(params = data.frame(a = 2, b = 10), mix = 0.4)
)

s1.simulations <- data.frame()
for (a in c(1, 3, 5)) {
  for (p in priorNames){

    prevData = list(prior = priorShapes[[p]])
    s1.rs <- webppl(paste(rsaHelpers, s1.model, sep = "\n"), 
          data = list(prior = priorShapes[[p]],
                      alpha = a), 
          data_var = "data")
    
    
    s1.simulations <- bind_rows(
      s1.simulations,
      s1.rs %>%
        mutate(endorsementProbNormalized = endorsementProb / sum(endorsementProb),
               posteriorProbUnnorm = endorsementProb * normalizedNeedProb,
               posteriorProbNorm = posteriorProbUnnorm / sum(posteriorProbUnnorm),
               prior = p, 
               alpha = a)
    )
      
    
    
    
    # for (refprev in c(0.1, 0.2, 0.3,0.4, 0.5, 0.6,  0.7, 0.8, 0.9)){
    # 
    #     s1.simulations <- bind_rows(
    #       s1.simulations,
    #       data.frame(s1.rs) %>%
    #         gather(model, endorsement) %>%
    #         mutate(prior = p, 
    #                  referent_prevalence =refprev,
    #                alpha = a)
    #     )
    # }

  print(p)
    
  }
}



s1.atc <- s1.simulations %>%
  group_by(alpha, prior) %>%
  summarize(endorse_prev = sum(posteriorProbNorm * prevalence)) 

s1.atc %>%
  spread(alpha, endorse_prev)



```



```{r}
s1.simulations %>%
  #filter(prior == "uniform") %>%
  ggplot(., aes ( x = referent_prevalence, y = endorsement,
                  color = model))+
  geom_point()+
  geom_line()+
  scale_color_solarized()+
  facet_wrap(~alpha, ncol = 1)
```

```{r}
# s1.atc <- s1.simulations %>%
#   #filter(prior == "uniform", model == "generic") %>%
#   rowwise() %>%
#   mutate(x = paste(rbinom(n = 50, size = 1, prob= endorsement),
#                    collapse = "_")) %>%
#   separate(x, into =paste("S", seq(1, 50), sep = "")) %>%
#   gather(subj, resp, starts_with("S")) %>%
#   mutate(resp = as.numeric(resp)) %>%
#   filter(resp == 1) %>%
#   group_by(subj, prior, model, alpha) %>%
#   summarize(atc = mean(referent_prevalence)) %>%
#   ungroup() %>%
#   group_by(prior, model, alpha) %>%
#   multi_boot_standard(col = "atc")

l0.averages <- sims.combined %>%
  filter(!(src == "priors")) %>%
  group_by(PriorShape,
           src, alpha, cost) %>%
  summarize(expval = mean(state))


m.gen.asym <- left_join(
  s1.atc %>%
    ungroup() %>% rename(src = model,
                    PriorShape = prior) %>%
    mutate(src = factor(src, 
                        levels = c("some","most","generic"),
                        labels = c("fixed_0.1", "fixed_0.5", "posteriors"))),
  l0.averages %>% ungroup() %>% select(-alpha, -cost)
) %>%
  select(-ci_lower, -ci_upper) %>%
  rename(S1 = mean, L0 = expval) %>%
  gather(model, expval, S1, L0)

bind_rows(
  l0.averages %>% ungroup() %>% filter(src == "posteriors") %>% select(-src, -cost) %>% mutate(src = "L0"),
  s1.atc %>% 
    rename(PriorShape = prior, expval = endorse_prev) %>%
    mutate(src = "S1")
) %>%
  ggplot(., aes(x = alpha, y = expval, fill = src))+
  geom_col(position= position_dodge(), color = 'black')+
  #geom_errorbar(position = position_dodge())+
  facet_wrap(~PriorShape)+
  ylim(0, 1)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
  

m.gen.asym %>%
  filter(src == "posteriors") %>%
  mutate(src = factor(src),
         PriorShape = factor(PriorShape, levels = c("accidental_rare", "uniform", "biological_rare")),
         model = factor(model, levels = c("S1", "L0"), labels = c("Truth conditions", "Implied prevalence"))) %>%
  ggplot(., aes(x = alpha, y = expval, fill = model))+
  geom_col(position= position_dodge(), color = 'black')+
  #geom_errorbar(position = position_dodge())+
  facet_wrap(~PriorShape)+
  ylim(0, 1)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

#save(m.gen.asym, s1.simulations, file = "../paper/cached_results/modelSims-asymmetry.RData")
```


```{r saveResults}
#save(sims.priors, sims.uncertain.thresholds, sims.fixed.thresholds,s1.simulations.relabeled, file = "../paper/cached_results/modelSims-priors_fixedT_uncertainT_speaker.RData")
```


# Schematic (uniform prior) figure

```{r schematicModel}
schematicModel <- '
var round = function(x){
  return Math.round(x*100)/100
}

var isNegation = function(utt){
  return (utt.split("_")[0] == "not")
};

var avoidEnds = function(x){
  return x >= 1 ? 0.99 : x == 0 ? 0.01 : x
}

var lb = 0, ub = 1, diff = 0.05;
var bins = _.range(lb, ub + diff, diff)

var DiscreteBeta = function(a, b){
  Infer({model: function(){
    categorical({
      vs:bins,
      ps:map(function(x){
        Math.exp(Beta({a, b}).score(avoidEnds(x)))
      }, bins)
    })
  }})
}

var utterances = [
  "gen",
  "null"
];

var utterancePrior = Infer({model: function(){
  return uniformDraw(utterances)
}});

var meaning = function(words, state, threshold){
  return words == "gen" ? state > threshold :
  true
};

var speakerOptimality = 3;
var speakerOptimality2 = 1;

var fixedThetalistener0 = cache(function(utterance, threshold) {
  Infer({model: function(){
    var state = sample(DiscreteBeta(1, 1));
    var m = meaning(utterance, state, threshold);
    condition(m);
    return state;
  }})
}, 10000);

var greaterThanThresholdBins = _.range(lb, ub, diff)
var lessThanThresholdBins = _.range(lb+diff, ub+diff, diff)

var litInterpreter = cache(function(utterance) {
  Infer({model: function(){
    var threshold = uniformDraw(greaterThanThresholdBins)

    var state = sample(DiscreteBeta(1, 1));
    var m = meaning(utterance, state, threshold);
    condition(m);
    return state
  }})
}, 10000);

var speaker1 = cache(function(state) {
  Infer({model: function(){
    var utterance = sample(utterancePrior);
    var L0 = litInterpreter(utterance);
    factor(speakerOptimality*L0.score(state));
    return utterance;
  }})
}, 10000);
'

listenerCall <- '
_.fromPairs(map(function(u){
  var post = litInterpreter(u)
  return [u, post]
}, utterances))
'

speakerCall <- '
_.flatten(
    map(function(s){
      var speakProbs = speaker1(s)
       return {  
          state: s,
          "gen": Math.exp(speakProbs.score("gen")),
          "null": Math.exp(speakProbs.score("null"))
        }
    }, bins)
)
'

literalListenerCall <- '
_.flatten(_.flatten(
map(function(tH){
    var l0posterior = fixedThetalistener0("gen", tH)
    display(expectation(l0posterior))
    map(function(s){
       return {  
          state: s,
          theta:tH, 
          literalPosterior: Math.exp(l0posterior.score(s))
        }
    }, bins)
}, greaterThanThresholdBins)
))
'
```

### Fixed thresholds


```{r schematicFixed}
rs.wp.l0 <- webppl(paste(schematicModel, literalListenerCall,  sep = '\n'))


fig.l0.thresholds <- ggplot(rs.wp.l0, aes( x = state, 
                                           y = literalPosterior, 
                                       group = theta))+
  geom_line(size = 2)+
  geom_vline(aes(xintercept = theta), 
             color = 'darkred', size = 2)+
  #scale_color_solarized()+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  #scale_color_continuous(limits = c(0, 1), breaks = c(0, 1))+
  ggtitle("truth-functional threshold = ")+
  ylab("Literal listener posterior probability")+
  xlab("Degree of happiness")+
  facet_wrap(~theta)+
  theme(text = element_text(size = 16))
```


Integrate out threshold (full interpretation model)

```{r schematicUncertain}
rs.listener.wp <- webppl(paste(schematicModel, listenerCall,  sep = '\n'))

rs.listener.wp.tidy <- bind_rows(
  data.frame(rs.listener.wp$gen) %>% 
    mutate(utterance = "gen"),
  data.frame(rs.listener.wp$null) %>% 
    mutate(utterance = "null")
)


rs.listener.wp.tidy.samples <- get_samples(
  rs.listener.wp.tidy %>% rename(prob = probs), 10000)

ggplot(rs.listener.wp.tidy.samples, 
       aes( x = support,fill = utterance, color = utterance))+
  geom_density(alpha = 0.4, size = 1.3)+
  scale_fill_solarized()+
  scale_color_solarized()+
  xlab("prevalence")+
  ylab("Posterior probability density")+
  scale_x_continuous(breaks =c(0, 1))+
  scale_y_continuous(breaks = c(0, 2))+
  #guides(fill = F, color = F)+
  ggtitle("prevalence posterior")

#ggsave("figs/lassiterL1_posteriors_wCost1,5_alpha1.png", width = 6, height = 4)
```


```{r schematicEndorsement}
rs.wp <- webppl(paste(schematicModel, speakerCall,  sep = '\n'))

rs.tidy <- data.frame(rs.wp) %>%
  gather(utt, prob, -state)

fig.thresholds <- ggplot(rs.tidy %>%
                           mutate(utt = factor(utt,
                                               levels=c("null","gen"))), 
                         aes( x = state, y = prob, fill = utt))+
  geom_col( 
           color = 'black')+
  #facet_wrap(~happy_theta)+
  scale_x_continuous(breaks = c(0, 0.5, 1))+
  scale_y_continuous(breaks = c(0, 0.5, 1))+
  ggtitle("truth-functional threshold = ")+
  ylab("Speaker probability of saying 'happy'")+
  xlab("Degree of happiness")+
  theme(text = element_text(size = 16))+
  scale_fill_solarized()

fig.thresholds
#ggsave(fig.thresholds, 
 #      file = "figs/lassiterS1_uttXstateXtheta_wCost.pdf", width = 7, height = 7)
```

```{r}
save(rs.wp.l0, rs.listener.wp.tidy.samples, rs.tidy,
     file = "../paper/cached_results/modelSims-uniform_fixedT_uncertainT_speaker.RData")
```

